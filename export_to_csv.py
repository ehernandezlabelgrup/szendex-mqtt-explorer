#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Script para exportar mensajes MQTT desde logs a CSV para Excel
Extrae todos los campos del JSON y los organiza en columnas
"""

import json
import csv
import re
import os
from datetime import datetime, timezone, timedelta
import sys

def adjust_timestamp_to_local(timestamp_str, hours_offset=1):
    """
    Convierte timestamp UTC a hora local sumando las horas especificadas
    """
    try:
        # Parsear el timestamp UTC
        if timestamp_str.endswith('Z'):
            # Formato ISO con Z (UTC)
            dt_utc = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
        else:
            # Asumir que es UTC si no tiene zona horaria
            dt_utc = datetime.fromisoformat(timestamp_str)
            dt_utc = dt_utc.replace(tzinfo=timezone.utc)
        
        # Sumar las horas especificadas
        dt_local = dt_utc + timedelta(hours=hours_offset)
        
        # Devolver en formato legible para Excel (sin zona horaria)
        return dt_local.strftime('%Y-%m-%d %H:%M:%S')
    except Exception as e:
        print(f"âš ï¸  Error ajustando timestamp '{timestamp_str}': {e}")
        return timestamp_str

def parse_log_file(log_file_path):
    """
    Lee el archivo de log y extrae todos los mensajes MQTT
    """
    messages = []
    current_message = {}
    
    print(f"ğŸ“– Leyendo archivo: {log_file_path}")
    
    with open(log_file_path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            
            # Detectar lÃ­nea de timestamp y topic
            if line.startswith('[') and '] cooler_mqtt/' in line:
                # Extraer timestamp y topic
                match = re.match(r'\[([^\]]+)\] (.+)', line)
                if match:
                    timestamp_str = match.group(1)
                    topic = match.group(2)
                    
                    # Ajustar timestamp a hora local (UTC+1)
                    local_timestamp = adjust_timestamp_to_local(timestamp_str, hours_offset=1)
                    
                    current_message = {
                        'timestamp': local_timestamp,
                        'timestamp_original': timestamp_str,
                        'topic': topic,
                        'line_number': line_num
                    }
            
            # Detectar lÃ­nea JSON
            elif line.startswith('{') and line.endswith('}'):
                try:
                    json_data = json.loads(line)
                    if current_message:
                        current_message['json_data'] = json_data
                        messages.append(current_message.copy())
                        current_message = {}
                except json.JSONDecodeError:
                    print(f"âš ï¸  Error JSON en lÃ­nea {line_num}: {line[:50]}...")
                    continue
    
    print(f"âœ… Encontrados {len(messages)} mensajes vÃ¡lidos")
    print(f"ğŸ• Timestamps ajustados a UTC+1 (hora local)")
    return messages

def flatten_json_data(json_data):
    """
    Aplana el JSON anidado para crear columnas separadas
    """
    flattened = {}
    
    for key, value in json_data.items():
        if isinstance(value, dict):
            # Para objetos anidados como SER
            for sub_key, sub_value in value.items():
                flattened[f"{key}_{sub_key}"] = sub_value
        else:
            flattened[key] = value
    
    return flattened

def export_to_csv(messages, output_file):
    """
    Exporta los mensajes a CSV con todas las columnas
    """
    if not messages:
        print("âŒ No hay mensajes para exportar")
        return
    
    # Recopilar todas las columnas posibles de los datos
    data_columns = set()
    
    for msg in messages:
        if 'json_data' in msg:
            flattened = flatten_json_data(msg['json_data'])
            data_columns.update(flattened.keys())
    
    # Construir orden especÃ­fico de columnas:
    # 1. timestamp (hora local UTC+1)
    # 2. SNU (identificador de nevera) 
    # 3. timestamp_original (hora UTC original)
    # 4. Resto de campos ordenados alfabÃ©ticamente
    
    final_columns = ['timestamp']
    
    # AÃ±adir SNU en segunda posiciÃ³n si existe
    if 'SNU' in data_columns:
        final_columns.append('SNU')
        data_columns.remove('SNU')
    
    # AÃ±adir timestamp original en tercera posiciÃ³n
    final_columns.append('timestamp_original')
    
    # AÃ±adir resto de campos ordenados alfabÃ©ticamente
    remaining_columns = sorted(list(data_columns))
    final_columns.extend(remaining_columns)
    
    print(f"ğŸ“Š Exportando {len(messages)} mensajes con {len(final_columns)} columnas")
    print(f"ğŸ’¾ Archivo destino: {output_file}")
    
    # Escribir CSV
    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=final_columns)
        
        # Escribir encabezados
        writer.writeheader()
        
        # Escribir datos
        for msg in messages:
            row = {
                'timestamp': msg.get('timestamp', ''),
                'timestamp_original': msg.get('timestamp_original', ''),
                'topic': msg.get('topic', ''),
                'line_number': msg.get('line_number', '')
            }
            
            if 'json_data' in msg:
                flattened = flatten_json_data(msg['json_data'])
                row.update(flattened)
            
            writer.writerow(row)
    
    print(f"âœ… ExportaciÃ³n completada!")
    print(f"ğŸ“‹ Columnas incluidas:")
    for i, col in enumerate(final_columns, 1):
        print(f"   {i:2d}. {col}")

def main():
    # Configurar rutas
    script_dir = os.path.dirname(os.path.abspath(__file__))
    logs_dir = os.path.join(script_dir, 'logs')
    
    # Buscar archivos de log
    log_files = []
    if os.path.exists(logs_dir):
        for file in os.listdir(logs_dir):
            if file.startswith('mqtt_messages_') and file.endswith('.txt'):
                log_files.append(os.path.join(logs_dir, file))
    
    if not log_files:
        print("âŒ No se encontraron archivos de log en:", logs_dir)
        return
    
    # Mostrar archivos disponibles
    print("ğŸ“ Archivos de log encontrados:")
    for i, log_file in enumerate(log_files, 1):
        size_mb = os.path.getsize(log_file) / (1024 * 1024)
        print(f"   {i}. {os.path.basename(log_file)} ({size_mb:.1f} MB)")
    
    # Seleccionar archivo (usar el mÃ¡s reciente por defecto)
    if len(log_files) == 1:
        selected_file = log_files[0]
        print(f"\nğŸ¯ Procesando: {os.path.basename(selected_file)}")
    else:
        # Tomar el mÃ¡s reciente
        selected_file = max(log_files, key=os.path.getmtime)
        print(f"\nğŸ¯ Procesando el mÃ¡s reciente: {os.path.basename(selected_file)}")
    
    # Procesar archivo
    messages = parse_log_file(selected_file)
    
    if messages:
        # Generar nombre de archivo CSV
        base_name = os.path.basename(selected_file).replace('.txt', '')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = os.path.join(script_dir, f"{base_name}_export_{timestamp}.csv")
        
        # Exportar
        export_to_csv(messages, output_file)
        
        print(f"\nğŸ‰ Â¡Listo! Archivo CSV creado:")
        print(f"ğŸ“ {output_file}")
        print(f"\nğŸ’¡ Puedes abrir este archivo directamente en Excel")
        print(f"ğŸ’¡ Las columnas estÃ¡n organizadas por importancia")
        
        # Mostrar estadÃ­sticas
        if messages:
            first_msg = messages[0]
            last_msg = messages[-1]
            print(f"\nğŸ“Š EstadÃ­sticas:")
            print(f"   ğŸ“… Primer mensaje: {first_msg.get('timestamp', 'N/A')}")
            print(f"   ğŸ“… Ãšltimo mensaje: {last_msg.get('timestamp', 'N/A')}")
            print(f"   ğŸ“¦ Total mensajes: {len(messages)}")
    else:
        print("âŒ No se encontraron mensajes vÃ¡lidos en el archivo")

if __name__ == "__main__":
    print("ğŸš€ MQTT Log to CSV Converter")
    print("=" * 50)
    main()